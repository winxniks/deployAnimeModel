import torch
import torchvision.transforms as transforms
from PIL import Image
import os
from pathlib import Path

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def load_model(model_path="checkpoints/final_netG.pth"):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ (Generator) –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ñ–æ—Ç–æ –≤ –∞–Ω–∏–º–µ.

    Args:
        model_path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É .pth —Å –≤–µ—Å–∞–º–∏ –º–æ–¥–µ–ª–∏.

    Returns:
        torch.nn.Module: –ì–æ—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º–µ eval –Ω–∞ –Ω—É–∂–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ.
    """
    from models.generator import Generator
    netG = Generator().to(device)
    netG.load_state_dict(torch.load(model_path, map_location=device))
    netG.eval()
    return netG


def get_no_aug_transform(input_path, size=256):
    """
    –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: resize, to tensor, normalize.

    Args:
        input_path (str): –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é.
        size (int): –¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 256).

    Returns:
        tuple: (—Ç–µ–Ω–∑–æ—Ä [1,3,H,W] –Ω–∞ device, –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä (w, h))
    """
    image = Image.open(input_path).convert('RGB')
    orig_size = image.size

    transform = transforms.Compose([
        transforms.Resize((size, size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])
    tensor = transform(image).unsqueeze(0).to(device)
    return tensor, orig_size


def tensor_to_pil_imagenet(pred_tensor, orig_size=None):
    """
    –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ ImageNet + –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ PIL.

    Args:
        pred_tensor (torch.Tensor): –í—ã—Ö–æ–¥ –º–æ–¥–µ–ª–∏ [1, C, H, W]
        orig_size (tuple): –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä (w, h), –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å.

    Returns:
        PIL.Image.Image: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.
    """
    pred_tensor = pred_tensor.detach().cpu().squeeze(0)
    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
    pred_tensor = pred_tensor * std + mean
    pred_tensor = torch.clamp(pred_tensor, 0.0, 1.0)
    img = transforms.ToPILImage()(pred_tensor)
    if orig_size is not None:
        img = img.resize(orig_size, Image.BICUBIC)
    return img


def tensor_to_pil_autonorm(pred_tensor, orig_size=None):
    """
    –ê–≤—Ç–æ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: min-max –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–Ω–∑–æ—Ä–∞.

    Args:
        pred_tensor (torch.Tensor): –í—ã—Ö–æ–¥ –º–æ–¥–µ–ª–∏.
        orig_size (tuple): –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä.

    Returns:
        PIL.Image.Image: –†–µ–∑—É–ª—å—Ç–∞—Ç.
    """
    pred_tensor = pred_tensor.detach().cpu().squeeze(0)
    min_val, max_val = pred_tensor.min(), pred_tensor.max()
    if max_val > min_val:
        pred_tensor = (pred_tensor - min_val) / (max_val - min_val)
    else:
        pred_tensor = torch.zeros_like(pred_tensor)
    pred_tensor = torch.clamp(pred_tensor, 0.0, 1.0)
    img = transforms.ToPILImage()(pred_tensor)
    if orig_size is not None:
        img = img.resize(orig_size, Image.BICUBIC)
    return img


def generate(model, input_path, use_imagenet=False):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞–Ω–∏–º–µ-—Å—Ç–∏–ª–∏–∑–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.

    Args:
        model (torch.nn.Module): –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å.
        input_path (str): –ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é.

    Returns:
        tuple: (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä, –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä)
    """
    with torch.no_grad():
        image_tensor, orig_size = get_no_aug_transform(input_path)
        pred_image = model(image_tensor)
        
    if use_imagenet:
        pil_img = tensor_to_pil_imagenet(pred_image, orig_size)
    else:
        pil_img = tensor_to_pil_autonorm(pred_image, orig_size)

    return pil_img


def save_image(pil_img, output_path):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.

    Args:
        pil_img (torch.Tensor): –í—ã—Ö–æ–¥ –º–æ–¥–µ–ª–∏.
        output_path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.
    """
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    pil_img.save(output_path)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")


def process_single_image(input_path, output_path, model, use_imagenet=False):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª.

    Args:
        input_path (str): –ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é.
        output_path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.
        model (torch.nn.Module): –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (—á—Ç–æ–±—ã –Ω–µ –≥—Ä—É–∑–∏—Ç—å –∫–∞–∂–¥—ã–π —Ä–∞–∑).
        use_imagenet (bool): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ImageNet-–¥–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é.

    Returns:
        bool: –£—Å–ø–µ—à–Ω–æ –ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ.
    """
    try:
        pred_image = generate(model, input_path)
        save_image(pred_image, output_path)
        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {input_path}: {e}")
        return False


def process_folder(input_folder, output_folder, model_path="deployAnimeModel/checkpoints/final_netG.pth", use_imagenet=False):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ.

    Args:
        input_folder (str): –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –≤—Ö–æ–¥–Ω—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.
        output_folder (str): –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
        model_path (str): –ü—É—Ç—å –∫ –≤–µ—Å–∞–º –º–æ–¥–µ–ª–∏.
        use_imagenet (bool): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ImageNet-–¥–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é.
    """
    # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}

    input_path = Path(input_folder)
    output_path = Path(output_folder)

    if not input_path.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {input_folder}")
        return

    # –°–æ–∑–¥–∞—ë–º –≤—ã—Ö–æ–¥–Ω—É—é –ø–∞–ø–∫—É
    output_path.mkdir(parents=True, exist_ok=True)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –æ–¥–∏–Ω —Ä–∞–∑
    print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    model = load_model(model_path)
    print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")

    # –°–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    image_files = [f for f in input_path.iterdir() if f.suffix.lower() in image_extensions]

    if not image_files:
        print(f"‚ö†Ô∏è –ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø–∞–ø–∫–µ: {input_folder}")
        return

    print(f"üöÄ –ù–∞–π–¥–µ–Ω–æ {len(image_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É...")

    success_count = 0
    for img_file in image_files:
        out_file = output_path / img_file.name
        if process_single_image(str(img_file), str(out_file), model, use_imagenet):
            success_count += 1

    print(f"‚úÖ –ì–æ—Ç–æ–≤–æ: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {success_count}/{len(image_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_folder}")


if __name__ == "__main__":
    input_dir = "data/input"
    output_dir = "data/output"

    process_folder(
        input_folder=input_dir,
        output_folder=output_dir,
        model_path="checkpoints/final_netG.pth",
        use_imagenet=False
    )